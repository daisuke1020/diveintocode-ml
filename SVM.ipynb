{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c64b7ae-ade4-44a8-9ad3-07e35c765ffc",
   "metadata": {},
   "source": [
    "# スクラッチを通してSVMを理解する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e1b2d-e7e0-4edb-9404-8147e49b6730",
   "metadata": {},
   "source": [
    "## 【問題1】ラグランジュの未定乗数法による最急降下"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6def7d-a317-4419-a81f-429cf8ccb739",
   "metadata": {},
   "source": [
    "### SVMの学習は、ラグランジュの未定乗数法を用います。サンプル数分のラグランジュ乗数 $\\lambda$ を用意して、以下の式により更新していきます。この計算を行うメソッドをScratchSVMClassifierクラスに実装してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eedb058-4c02-453c-9e33-d4ff6a8d6d38",
   "metadata": {},
   "source": [
    "$$\n",
    "λ_i^{new}=λ_i+α(1−∑^N_{j=1} λ_jy_iy_jk(x_i,x_j))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b8d1d0-58fb-4b17-8cb9-5420b5de35ce",
   "metadata": {},
   "source": [
    "### ここで $k(x_i, x_j)$ はカーネル関数です。線形カーネルの場合は次のようになります。他のカーネル関数にも対応できるように、この部分は独立したメソッドとしておきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7cf01b-813d-4310-85ff-03dc05eec142",
   "metadata": {},
   "source": [
    "$$\n",
    "k(x_i,x_j)=x_i^{T}x_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419da32-7d63-4d52-90bb-907e2c28a65e",
   "metadata": {},
   "source": [
    "### 条件として、更新毎に $\\lambda_i >= 0$を満たす必要があります。満たさない場合は $\\lambda_i = 0$とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8a692a-dced-4c58-a5ce-be1480e56fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _grad(self,X,y):\n",
    "    \n",
    "    #ラグランジュの未定乗数法による最急降下\n",
    "    \n",
    "    # サンプル数\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # lamの初期化\n",
    "    lam = np.random.rand(m)\n",
    "    \n",
    "    # lamとyを変形\n",
    "    lam = lam.reshape(-1,1)\n",
    "    y = y.reshape(-1,1)\n",
    "    \n",
    "    # lamの更新式\n",
    "    Kx = _kanel(X,X.T)\n",
    "    grad = np.sum(lam*(y@y.T)*Kx,axis = 0).reshape(-1,1)\n",
    "    lam = lam + lr*(1 - grad)\n",
    "    lam = np.where(lam < 0,0,lam)\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "def _kanel(self,X,y):\n",
    "    # カーネル関数のメソッド\n",
    "    return X @ y.T\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46857f92-137e-4477-9f93-ae52e69beb52",
   "metadata": {},
   "source": [
    "## 【問題2】サポートベクターの決定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707acc7-f159-4eac-84ee-a7fec7119423",
   "metadata": {},
   "source": [
    "### 計算したラグランジュ乗数 $\\lambda$ が設定した閾値より大きいサンプルをサポートベクターとして扱います。推定時にサポートベクターが必要になります。サポートベクターを決定し、インスタンス変数として保持しておくコードを書いてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672905c4-6d8c-4a6a-9db9-53028bc84d7d",
   "metadata": {},
   "source": [
    "### 閾値はハイパーパラメータですが、1e-5程度からはじめると良いでしょう。サポートベクターの数を出力させられるようにしておくと学習がうまく行えているかを確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a06059-a35e-4d57-a3b8-7d8f2f845c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# サポートベクターの決定\n",
    "def sv_n(self,X,y):\n",
    "    \n",
    "    # サポートベクターの取得\n",
    "    indx_sv = np.array([])\n",
    "    for i in range(m):\n",
    "        # 閾値よりlamが高ければ、そこに対応するXを追加\n",
    "        if self.lam[i] > threshold:\n",
    "            indx_sv = np.append(indx_sv,i)\n",
    "            \n",
    "    return indx_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8594bc2-8195-4b71-af5a-b7e55963d9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b11804c9-c9f1-4895-a587-2d226a0274eb",
   "metadata": {},
   "source": [
    "## 【問題3】推定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84ef60-bf0d-4d30-803d-ad436c4eb7a1",
   "metadata": {},
   "source": [
    "### 推定時には、推定したいデータの特徴量とサポートベクターの特徴量をカーネル関数によって計算します。求めた $f(x)$ の符号が分類結果です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1363a6d3-e13a-4424-97e3-0c872489b140",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x)=∑^N_{n=1} λ_ny_{sv_n}k(x,s_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc56454a-47b7-453a-a376-fb610e93e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self,X):\n",
    "    # 予測する\n",
    "    hyper = X @ self.w + self.b\n",
    "    \n",
    "    # 分類結果を１か−１で返す\n",
    "    result = np.where(hyper > 0,1,-1)\n",
    "    \n",
    "    # 予測値を返却する\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481ca084-5e94-4234-a5a6-f3ce3460a1ac",
   "metadata": {},
   "source": [
    "## 【問題4】学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c9cf4a-9cdd-46b9-8d70-9496b12fc20a",
   "metadata": {},
   "source": [
    "## 機械学習スクラッチ入門のSprintで用意したシンプルデータセット1の2値分類に対してスクラッチ実装の学習と推定を行なってください。\n",
    "## scikit-learnによる実装と比べ、正しく動いているかを確認してください。\n",
    "## AccuracyやPrecision、Recallなどの指標値はscikit-learnを使用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45ab736d-1997-44ef-8b04-fd90492f7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSVMClassifier():\n",
    "    \"\"\"\n",
    "    SVM分類器のスクラッチ実装\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    kernel : str\n",
    "      カーネルの種類。線形カーネル（linear）か多項式カーネル（polly）\n",
    "    threshold : float\n",
    "      サポートベクターを選ぶための閾値\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.n_support_vectors : int\n",
    "      サポートベクターの数\n",
    "    self.index_support_vectors : 次の形のndarray, shape (n_support_vectors,)\n",
    "      サポートベクターのインデックス\n",
    "    self.X_sv :  次の形のndarray, shape(n_support_vectors, n_features)\n",
    "      サポートベクターの特徴量\n",
    "    self.lam_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "      サポートベクターの未定乗数\n",
    "    self.y_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "      サポートベクターのラベル\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, kernel='linear',threshold=1e-5,verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.kernel = kernel\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def fit(self, X, y, X_test=None, y_test=None):\n",
    "        \"\"\"\n",
    "        SVM分類器を学習する。検証データが入力された場合はそれに対する精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        # サンプル数\n",
    "        self.m = X.shape[0]\n",
    "        \n",
    "        # 特徴量数\n",
    "        self.n = X.shape[1]\n",
    "               \n",
    "        # 最急降下法を用いて双対問題を解く\n",
    "        for _ in range(self.iter):\n",
    "            self._grad(X,y)\n",
    "        \n",
    "        #if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            #print()\n",
    "        pass\n",
    "    \n",
    "    def _grad(self,X,y):\n",
    "    \n",
    "        #ラグランジュの未定乗数法による最急降下\n",
    "    \n",
    "        # サンプル数\n",
    "        m = X.shape[0]\n",
    "\n",
    "        # lamの初期化\n",
    "        self.lam = np.random.rand(m)\n",
    "\n",
    "        # lamとyを変形\n",
    "        self.lam = self.lam.reshape(-1,1)\n",
    "        self.y = y.reshape(-1,1)\n",
    "\n",
    "        # lamの更新式\n",
    "        Kx = self._kanel(X,X)\n",
    "        grad = np.sum(self.lam*(y@y.T)*Kx,axis = 0).reshape(-1,1)\n",
    "        lam = self.lam + self.lr*(1 - grad)\n",
    "        lam = np.where(lam < 0,0,lam)\n",
    "\n",
    "        return lam\n",
    "\n",
    "    def _kanel(self,X,y):\n",
    "        # カーネル関数のメソッド\n",
    "         \n",
    "        return X @ y.T\n",
    "    \n",
    "    def _sv_n(self,X):\n",
    "        # パラメータを０で初期化\n",
    "        #\n",
    "#         self.w = np.zeros(self.m)\n",
    "#         self.b = 0\n",
    "    \n",
    "        # サポートベクターの取得\n",
    "        indx_sv = np.array([])\n",
    "        for i in range(125):\n",
    "            \n",
    "            # 閾値よりlamが高ければ、そこに対応するインデックスの番号を追加\n",
    "            if self.lam[i] > 1e-5:\n",
    "                indx_sv =np.append(indx_sv,i)\n",
    "\n",
    "        # wを計算\n",
    "#         for i in indx_sv:\n",
    "#             self.w += self.lam[i]*y[i]*X[i]\n",
    "\n",
    "        # bを計算\n",
    "#         for i in indx_sv:\n",
    "#             self.b += y[i] - (self.w @ X[i])\n",
    "#         self.b /= len(indx_sv)\n",
    "        \n",
    "        return indx_sv\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        SVM分類器を使いラベルを推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            SVM分類器による推定結果\n",
    "        \"\"\"\n",
    "        \n",
    "        # 予測する\n",
    "        indx_sv = self._sv_n(X)\n",
    "        lam_y =np.array([])\n",
    "        for j in range(X.shape[0]):\n",
    "            for i in range(len(indx_sv)):\n",
    "                ind_n = int(indx_sv[i])\n",
    "                lam_yy = self.lam[ind_n]*self.y[ind_n]\n",
    "                \n",
    "                x_kanel = self._kanel(X[j],X[ind_n])\n",
    "                \n",
    "                lam_y_ = np.sum(lam_yy*x_kanel)\n",
    "            lam_y = np.append(lam_y,lam_y_)\n",
    "\n",
    "        # 分類結果を１か−１で返す\n",
    "        result = np.where(lam_y > 0,-1,1)\n",
    "\n",
    "        # 予測値を返却する\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d47d458-db8e-488d-ae01-3c4d9458df28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.7604608   1.31649324]\n",
      "[-2.35253112  0.5177154 ]\n",
      "4.823107639160986\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings                      #ワーニング関連のモジュール？\n",
    "warnings.filterwarnings('ignore')    #ワーニングが消える？\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n",
    "f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n",
    "X = np.concatenate([f0, f1])\n",
    "y = np.concatenate([\n",
    "    np.full(n_samples // 2, 1),\n",
    "    np.full(n_samples // 2, -1)\n",
    "])\n",
    "print(X[6])\n",
    "print(X[8])\n",
    "print(X[6]@X[8].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3d40b6-de6c-4707-b088-bee4c1ebb72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 375)\n",
      "(375, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "#print(y)\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "print(X_train.T.shape)\n",
    "print(y_train.reshape(-1,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f15ebabc-785e-4e29-b261-f8884e55a59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124.]\n",
      "[-1  1  1  1 -1  1  1 -1 -1 -1 -1  1 -1 -1  1  1  1 -1  1  1  1  1 -1 -1\n",
      "  1 -1  1  1  1 -1  1  1  1 -1  1  1  1  1 -1 -1  1 -1 -1  1 -1 -1  1  1\n",
      "  1  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1  1  1  1  1  1  1 -1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1 -1  1 -1  1  1  1 -1  1  1  1 -1  1 -1\n",
      "  1 -1  1 -1 -1 -1 -1  1  1  1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1  1  1  1\n",
      "  1  1 -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "'''SVMモデルの作成'''\n",
    "\n",
    "#モジュール読み込み、モデル構築\n",
    "svm = ScratchSVMClassifier(num_iter=1000, lr = 0.005, kernel='linear',verbose=False)\n",
    "\n",
    "#モデルの学習\n",
    "\n",
    "svm.fit(X_train,y_train,X_test,y_test)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(svm._sv_n(X_test))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df1f9cc1-4106-4b2e-a516-f9985edd7989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[38 17]\n",
      " [ 5 65]]\n",
      "accuracy =  0.824\n",
      "precision =  0.7926829268292683\n",
      "recall =  0.9285714285714286\n",
      "f1 score =  0.855263157894737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print('confusion matrix = \\n', confusion_matrix(y_test, y_pred))\n",
    "print('accuracy = ', accuracy_score(y_test, y_pred))\n",
    "print('precision = ', precision_score(y_test, y_pred))\n",
    "print('recall = ', recall_score(y_test, y_pred))\n",
    "print('f1 score = ', f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113ce9b-e1ec-4e65-bb03-b18bdfbab5e9",
   "metadata": {},
   "source": [
    "## 【問題5】決定領域の可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b4468-75b6-4016-981f-97e86006b6a0",
   "metadata": {},
   "source": [
    "### 決定領域を可視化してください。\n",
    "### 以下の例のようにサポートベクターは異なる色で示してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e256ac8-ff4a-4256-a3a2-f34704d5fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def decision_region(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica']):\n",
    "    \"\"\"\n",
    "    2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n",
    "    背景の色が学習したモデルによる推定値から描画される。\n",
    "    散布図の点は訓練データまたは検証データである。\n",
    "    Parameters\n",
    "    ----------------\n",
    "    X : ndarray, shape(n_samples, 2)\n",
    "        特徴量\n",
    "    y : ndarray, shape(n_samples,)\n",
    "        ラベル\n",
    "    model : object\n",
    "        学習したモデルのインスンタスを入れる\n",
    "    step : float, (default : 0.1)\n",
    "        推定値を計算する間隔を設定する\n",
    "    title : str\n",
    "        グラフのタイトルの文章を与える\n",
    "    xlabel, ylabel : str\n",
    "        軸ラベルの文章を与える\n",
    "    target_names= : list of str\n",
    "        凡例の一覧を与える\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    scatter_color = ['red', 'blue']\n",
    "    contourf_color = ['pink', 'skyblue']\n",
    "    n_class = 2\n",
    "    # pred\n",
    "    a = np.min(X[:,0])-0.5  # Xの０列目の最小値　　-0.5\n",
    "    b = np.max(X[:,0])+0.5  # Xの０列目の最大値 +0.5\n",
    "    c = np.min(X[:,1])-0.5  # Xの1列目の最小値　　-0.5\n",
    "    d = np.max(X[:,1])+0.5  # Xの1列目の最大値 +0.5\n",
    "    ab = np.arange(a,b,step)  #(start,stop,step)の公差配列\n",
    "    cd = np.arange(c,d,step)  #(start,stop,step)の公差配列\n",
    "    \n",
    "    mesh_f0, mesh_f1  = np.meshgrid(ab,cd)   # 引数に合わせた格子を作成（X=横、y=縦）\n",
    "    \n",
    "    e = np.ravel(mesh_f0)  # ravelで引数を平坦化\n",
    "    f = np.ravel(mesh_f1)  # ravelで引数を平坦化\n",
    "    mesh = np.c_[e,f]  # vstackと同じ、横結合  (eとfの長さが足される)\n",
    "    g = model.predict(mesh)  # meshをpredict\n",
    "    y_pred = g.reshape(mesh_f0.shape)\n",
    "#     print(y_pred)\n",
    "#     print(mesh_f0)\n",
    "#     print(mesh_f1)\n",
    "    # plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    # 等高線で分けた時の配色\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    # 等高線\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "    for i, target in enumerate(set(y)):\n",
    "        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n",
    "    plt.scatter()\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed3e45-d00d-4cb1-a884-b54af7f5ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_region(X_test, y_test, svm, step=0.01, title='ScratchSVM', xlabel='xlabel', ylabel='ylabel', target_names=['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788aa4c-d3bf-4354-944e-e91d5db9267c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc21989e-ecfc-4619-ae02-8cedf216e093",
   "metadata": {},
   "source": [
    "## 扱いやすい形にする\n",
    "「$\\frac{M}{||w||}$ を $y_{i}(w^{T}x_{i})\\geq M$ という条件の元で最大化する $w$ や $M$ を求める問題」\n",
    "\n",
    "\n",
    "と表現できます。条件式は $x_{i}$ に訓練データのすべての点を入れて成り立つ必要があります。まだまだややこしいですが、これをMで割ってしまいます。そうすると、\n",
    "\n",
    "\n",
    "「$\\frac{1}{||w||}$ を $y_{i}(\\frac{w^{T}}{M}x_{i})\\geq 1$ という条件の元で最大化する $w$ や $M$ を求める問題」\n",
    "\n",
    "\n",
    "になり、さらに $w^{T} \\gets \\frac{w^{T}}{M}$ と置き換えてしまいます。\n",
    "\n",
    "\n",
    "そうすれば、\n",
    "\n",
    "\n",
    "「 $\\frac{1}{||w||}$ を $y_{i}(w^{T}X_{i})\\geq 1$ という条件の元で最大化する $w$を求める問題」\n",
    "\n",
    "\n",
    "まで簡単化できます。 $\\frac{1}{||w||}$ を最大化するというのは $||w||$ を最小化することと同じです。これを後々さらに扱いやすくするために $\\frac{1}{2}||w||^2$ を最小化すると考えます。よって、\n",
    "\n",
    "\n",
    "「 $\\frac{1}{2}||w||^2$ を $y_{i}(w^{T}x_{i})\\geq 1$ という条件の元で最小化する $w$ を求める問題」\n",
    "\n",
    "\n",
    "とすることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7563aa9a-16f1-4522-b531-9e1fada942a5",
   "metadata": {},
   "source": [
    "## 解きやすい問題にする（双対化）\n",
    "こういった不等式制約を持つ最適化問題は次のように ラグランジュの未定乗数法 で置き換えられることが知られています。\n",
    "\n",
    "\n",
    "なお、このように難しい問題を別の簡単な問題に言い換えることを 双対化する といいます。\n",
    "\n",
    "\n",
    "ラグランジュの未定乗数法を用いると以下のラグランジュ関数が得られます。\n",
    "\n",
    "$$\n",
    "L(w,λ)=1/2||w||^2−∑^N_{i=1} λ_i{y_i(w^Tx_i)−1}\n",
    "$$\n",
    "\n",
    "$\\lambda$ はラグランジュ乗数と呼ばれる数で、0以上の値です。これを $w$について微分し、0に等しいと置くと、次の式が得られます。\n",
    "\n",
    "$$\n",
    "w=∑^N_{i=1} λ_iy_ix_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80410744-5313-460e-95f5-8e9b8e297d84",
   "metadata": {},
   "source": [
    "を $\\lambda_{i} \\geq 0$ かつ $\\sum_{n=1}^{N}\\lambda_{i}y_{i} = 0$ の条件の元で最大化するときの $\\lambda_{i}$ を探す問題に双対化できます。\n",
    "\n",
    "\n",
    "この形になれば、$\\lambda$ を勾配降下法により求めることができます。$w$は出てきませんが、得られる結果は同じです。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8869d0-6a26-4293-bed9-0427cf615a1e",
   "metadata": {},
   "source": [
    "## カーネル\n",
    "最後の式の $x_{i}^{T} x_j$ の部分を $k(x_i, x_j)$ という関数に置き換えます。この関数を カーネル関数 と呼びます。\n",
    "\n",
    "$$\n",
    "L(λ) = ∑^N_{i=1} λ_i−1/2∑^N_{i=1} ∑^N_{j=1} λ_iλ_jｙ_iｙ_j(x_i,x_j)\n",
    "$$\n",
    "\n",
    "この式が問題1の最急降下法の式の元になります。\n",
    "\n",
    "\n",
    "カーネル関数は $x_{i}^{T} x_j$ ではないさまざまな計算に置き換えることができます。この部分を置き換えるだけで、元の特徴量を 高次元空間 に移動させたことと同じ結果が得られ、高い分類性能を得ることができます。これを カーネルトリック と呼びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d0d27-f024-484c-ba11-4bc83f5ba505",
   "metadata": {},
   "source": [
    "## 高次元へ移す簡単な例\n",
    "次の図のように1次元上に2色の点があるとします。これらを直線一本を引くことで分けることは不可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e1cfb-d04d-41a7-9180-5aa17d656572",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "023bc06d-3a94-4811-81a5-bb3e8313719c",
   "metadata": {},
   "source": [
    "しかし、例えば以下のように変換してみると直線でも分けられそうです。\n",
    "$x^2=2.5$ あたりに線を引くことになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5648b092-fd0c-4d29-a458-8871d2edeb29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13e70dca-717f-4fee-bb15-910c30f14867",
   "metadata": {},
   "source": [
    "これは$x^2$を計算し、それを縦軸にプロットしたグラフです。1次元だったデータを $\\phi(x)=x^2$ の関数により高次元（2次元）へと移動しました。\n",
    "\n",
    "\n",
    "こういったことをSVMはカーネルトリックにより行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b68e0f6-bd85-44c9-b476-8a054565b547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9349c0-e791-42d2-9bbd-d7d31fe8b9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
